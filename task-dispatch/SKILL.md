---
name: task-dispatch
description: 子代理任务分配和模型选择策略。分配子任务、选择模型、spawn子代理时参考。
---

# 任务分配与模型选择

## 核心原则

**Copilot 模型全部无限用，不考虑经济性。只考虑效率和质量的平衡。**

**顶级模型优先用**：Opus 4.6、Opus 4.5、GPT-5.2、GPT-5.1 能用就用。
只有一次性大量任务或确实简单的任务，才考虑用其他模型分担。

## 脚本优先原则（LLM节省法则）

**能用脚本做的事，绝不用LLM。** LLM只用于需要决策和分析的场景。

### 脚本做（不用LLM）：
- 数据获取/行情拉取（定时脚本循环）
- 规则化的止盈止损执行（纯阈值判断）
- 数据刷新/看板更新
- 定时备份/文件同步
- 格式化通知推送（飞书直调API）
- 监控/报警（阈值触发）

### LLM做（需要智能）：
- 交易决策确认（买入判断、仓位分配）
- 复盘分析（5-Why、交叉质询）
- 市场解读/新闻分析
- 策略参数调整建议
- 异常情况处理（脚本兜不住的）

### 设计新任务时：
1. 先问"这个能不能用纯脚本+规则搞定？"
2. 能 → 写脚本，cron/daemon运行
3. 不能 → 用LLM，但尽量缩小LLM参与的范围
4. 混合场景 → 脚本做数据准备+规则判断，只在需要时触发LLM

## 模型分配策略

### 第一梯队（默认使用）
| 模型 | 用法 |
|------|------|
| Claude Opus 4.6 | 主会话对话/决策/验收 |
| GPT-5.2 | 子代理·内容生成/创作/复杂推理 |
| GPT-5.1 | 子代理·深度推理/分析 |
| Claude Opus 4.5 | 子代理·复杂创作（Opus系备选） |

### 第二梯队（大量/简单任务时分担）
| 模型 | 用法 |
|------|------|
| Claude Sonnet 4.5 | 通用+Agent任务 |
| GPT-5 mini | 轻量推理 |
| GPT-4.1 | 脚本/文件操作/工具调用 |

### Fallback only
| 模型 | 说明 |
|------|------|
| Gemini 系列 | ⚠️ 有限免费额度，不主动分配 |

## 三模型并行搜索（信息调研类任务必用）

当用户要求搜索**价格、新闻、数据、信息**等需要全网调研的任务时，**必须三个子代理同时做**：

| 子代理 | 模型 |
|--------|------|
| 搜索-A | `openai/gpt-5.2` |
| 搜索-B | `github-copilot/claude-opus-4.5` |
| 搜索-C | `github-copilot/claude-opus-4.6` |

### 搜索类任务必须使用OSINT skill

**所有需要多渠道搜索、调研、估价、比价、信息收集的任务，子代理的prompt中必须指示使用 osint-investigation skill。** OSINT skill提供系统化的信息收集方法论，比简单web_search更全面。

适用场景：
- 二手车/商品估价（多平台比价）
- 市场调研/竞品分析
- 人物/公司背景调查
- 事件追踪/舆情分析
- 价格趋势研究

子代理prompt中加入：
```
请先读取 /root/.openclaw/workspace/skills/osint-investigation/SKILL.md，按照OSINT方法论进行系统化信息收集。
```

### 流程
1. **并行派发**：同一任务同时 spawn 3个子代理，相同 prompt
2. **收集结果**：等待全部完成（sleep 30 + sessions_list轮询，最多8轮/4分钟）
3. **交叉质询（层层追问式，不是平行罗列！）**：
   对三份结果中的每个分歧点，做追问链分析：
   ```
   分歧: 模型A说X，模型B说Y，模型C说Z
   Why 1: 为什么会有这个分歧？各自的数据来源是什么？
   → 回答: [A引用了xx来源，B引用了yy来源...]
   Why 2: (基于上面) xx和yy来源哪个更可靠？有没有第三方验证？
   → 回答: [xx是官方数据，yy是二手引用...]
   Why 3: (基于上面) 即使来源可靠，数据时效性如何？是否过时？
   → 回答: [xx是今天的，yy是上周的...]
   → 结论: 采纳X，因为...
   ```
   - 数据一致的部分 → 高置信度采纳
   - 数据矛盾的部分 → 用上述追问链深挖，不能简单投票了事
   - 某个模型独有的发现 → 追问为什么其他模型没发现，评估可信度
4. **收敛输出**：整合为一份统一的、经过验证的结论，发给用户

### 为什么这样做
- 不同模型搜索策略不同，覆盖面更广
- 三份独立结果交叉验证，减少幻觉和数据错误
- 类似量化交易系统的多模型复盘方法论

## 并行控制

- **子代理并行上限：3个**（三模型搜索场景可同时3个）
- 多任务场景：分批执行，前一批完成（或至少1个完成）再启动下一批

## 任务粒度原则

- **每个子代理任务要聚焦**：1科1套，不要让一个子代理做太多
- 任务越大，失败/截断/质量下降的风险越高

## 教训

- GPT-4o 生成长内容会截断（物理试卷 12KB→2KB），代价是翻倍重做
- GPT-5.2 + write工具 + 超长content = socket超时断开，**改用 exec+heredoc 写文件**
- GPT-5 mini 做大任务会请求确认/输出不稳定，**重任务直接上 5.2**
- 子代理说完成不能直接信，**必须验收**（检查文件大小、内容完整性）
- 不要为了省着用小模型再返工，直接用强模型一步到位
- **搬砖活绝不在主对话做**：写代码、调API、debug、部署配置、数据抓取等一律spawn子代理。主对话只做决策+验收+沟通。否则主对话卡住，大冬瓜等得烦。
