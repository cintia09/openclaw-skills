---
name: task-dispatch
description: 子代理任务分配和模型选择策略。分配子任务、选择模型、spawn子代理时参考。
---

# 任务分配与模型选择

## 核心原则

**Copilot 模型全部无限用，不考虑经济性。只考虑效率和质量的平衡。**

**顶级模型优先用**：Opus 4.6、Opus 4.5、GPT-5.2、GPT-5.1 能用就用。
只有一次性大量任务或确实简单的任务，才考虑用其他模型分担。

## 模型分配策略

### 第一梯队（默认使用）
| 模型 | 用法 |
|------|------|
| Claude Opus 4.6 | 主会话对话/决策/验收 |
| GPT-5.2 | 子代理·内容生成/创作/复杂推理 |
| GPT-5.1 | 子代理·深度推理/分析 |
| Claude Opus 4.5 | 子代理·复杂创作（Opus系备选） |

### 第二梯队（大量/简单任务时分担）
| 模型 | 用法 |
|------|------|
| Claude Sonnet 4.5 | 通用+Agent任务 |
| GPT-5 mini | 轻量推理 |
| GPT-4.1 | 脚本/文件操作/工具调用 |

### Fallback only
| 模型 | 说明 |
|------|------|
| Gemini 系列 | ⚠️ 有限免费额度，不主动分配 |

## 三模型并行搜索（信息调研类任务必用）

当用户要求搜索**价格、新闻、数据、信息**等需要全网调研的任务时，**必须三个子代理同时做**：

| 子代理 | 模型 |
|--------|------|
| 搜索-A | `openai/gpt-5.2` |
| 搜索-B | `github-copilot/claude-opus-4.5` |
| 搜索-C | `github-copilot/claude-opus-4.6` |

### 流程
1. **并行派发**：同一任务同时 spawn 3个子代理，相同 prompt
2. **收集结果**：等待全部完成
3. **交叉质询**：主会话（Opus 4.6）对三份结果进行对比分析
   - 数据一致的部分 → 高置信度采纳
   - 数据矛盾的部分 → 追问或再搜验证
   - 某个模型独有的发现 → 评估可信度后决定采纳
4. **收敛输出**：整合为一份统一的、经过验证的结论，发给用户

### 为什么这样做
- 不同模型搜索策略不同，覆盖面更广
- 三份独立结果交叉验证，减少幻觉和数据错误
- 类似量化交易系统的多模型复盘方法论

## 并行控制

- **子代理并行上限：3个**（三模型搜索场景可同时3个）
- 多任务场景：分批执行，前一批完成（或至少1个完成）再启动下一批

## 任务粒度原则

- **每个子代理任务要聚焦**：1科1套，不要让一个子代理做太多
- 任务越大，失败/截断/质量下降的风险越高

## 教训

- GPT-4o 生成长内容会截断（物理试卷 12KB→2KB），代价是翻倍重做
- GPT-5.2 + write工具 + 超长content = socket超时断开，**改用 exec+heredoc 写文件**
- GPT-5 mini 做大任务会请求确认/输出不稳定，**重任务直接上 5.2**
- 子代理说完成不能直接信，**必须验收**（检查文件大小、内容完整性）
- 不要为了省着用小模型再返工，直接用强模型一步到位
